{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Famous Convolutional Neural Network Architectures - Part #1\n",
    "In [last post](), we went over the basics of a convolution layer. We discussed the smallest details of how it works and how we can stack multiple layers to define a complete neural network architecture.\n",
    "\n",
    "Let's go over some of the powerful Convolutional Neural Network which laid the foundation of today's Computer Vision achievements, achieved using Deep Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index\n",
    "If you are here for a particular architecture, use below links to jump to it.\n",
    "1. LeNet-5\n",
    "  - Architecture\n",
    "  - Code\n",
    "2. AlexNet\n",
    "  - Architecture\n",
    "  - Code\n",
    "3. VGGNet\n",
    "  - Architecture\n",
    "  - Code\n",
    "4. GoogLeNet/Inception Model\n",
    "  - Architecture\n",
    "  - Code\n",
    "5. ResNet\n",
    "  - Architecture\n",
    "  - Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet-5 - LeCun et al\n",
    "[LeNet-5](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf), a 7 layer Convolutional Neural Network, was deployed in many banking systems to recognize hand-written number on cheques.\n",
    "\n",
    "|![](images/lenet.jpg)|\n",
    "|:-------------------:|\n",
    "|*Source:  [Gradient based learning applied to document recognition fig 2](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)*|\n",
    "\n",
    "### LeNet-5 - Architecture\n",
    "The hand-written numbers were digitized into grayscale images of pixel size - 32x32. At that time the computational capacity was limited and hence the the technique wasn't scalable to large scale images.\n",
    "\n",
    "Let's understand the architecture of the model. The model contained 7 layers excluding the input layer. Since it is a relatively small architecture let's go layer by layer:\n",
    "\n",
    "1. **Layer 1**: A convolutional layer with kernel size of 5x5, stride of 1x1 and 6 kernels in total. So the input image of size 32x32x1 gives an output of 28x28x6. Total params in layer = 5 * 5 * 6 + 6 (bias terms)\n",
    "2. **Layer 2**: A pooling layer with 2x2 kernel size, stride of 2x2 and 6 kernels in total. This pooling layer acted a little differently than what we discussed in previous post. The input values in the receptive were summed up and then were multiplied to a trainable parameter (1 per filter), the result was finally added to a trainable bias (1 per filter). Finally, sigmoid activation was applied to the output. So, the input from previous layer of size 28x28x6 gets sub-sampled to 14x14x6. Total params in layer = \\[1 (trainable parameter) + 1 (trainable bias)\\] * 6 (number of filters) = 12\n",
    "3. **Layer 3**: Same as **Layer 1** this layer is a convolutional layer with same configuration except it has 16 filters instead of 6. So the input from previous layer of size 14x14x6 gives an output of 10x10x16. Total params in layer = 5 * 5 * 16 + 16 = 416.\n",
    "4. **Layer 4**: Again similar to **layer 2**, this layer is a pooling layer with 16 filters this time around. Remember the outputs are passed through sigmoid activation function. The input of size 10x10x16 from previous layers gets sub-sampled to 5x5x16. Total params in layer = (1 + 1) * 16 = 32\n",
    "5. **Layer 5**: This time around we have a convolutional layer with 5x5 kernel size and 120 filters. There is no need to event consider strides as the input size is 5x5x16 so we will get an output of 1x1x120. Total params in layer = 5 * 5 * 120 = 3000\n",
    "6. **Layer 6**: This is a dense layer with 84 parameters. So, the input of 120 units is converted to 84 units. Total params = 84 * 120 + 84 = 10164. The activation function used here was rather a unique one. I'll say you can just try out any of your choice here as the task is pretty simple one by today's standards.\n",
    "7. **Output Layer**: Finally, a dense layer with 10 units is used. Total params = 84 * 10 + 10 = 924.\n",
    "\n",
    "Skipping over the details of loss function used and why it was used. I would suggest using cross-entropy loss with softmax activation in the last layer. Try out different training schedules and learning rates.\n",
    "\n",
    "### LeNet-5 - Code\n",
    "**ADD Git gist here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet - Krizhevsky et al\n",
    "In 2012 a jaw dropping moment occured when Hinton's Deep Neural Network reduced the top-5 loss from 26% to 15.3% in the world's most significant computer vision challenge - [imagenet](http://www.image-net.org/).\n",
    "\n",
    "The network was very similar to LeNet but was much more deeper and had around 60 million parameters.\n",
    "\n",
    "|![](images/alexnet.jpg)|\n",
    "|:---------------------:|\n",
    "|*Source: [ImageNet Classification with Deep Convolutional Neural Networks fig 2](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)*|\n",
    "\n",
    "### AlexNet - Architecture\n",
    "Well that figure certainly looks scary. This is because the network was split into two halves each trained simultaneously on two different GPUs. Let's make this a little bit easy for us and brings a simpler version into the picture.\n",
    "\n",
    "|![](images/alexnet2.jpg)|\n",
    "|:----------------------:|\n",
    "|*Source: [Deep Learning Specialization](deeplearning.ai)*|\n",
    "\n",
    "The architecture consists of **5 Convolutional Layers** and **3 Fully Connected Layers**. These 8 layers combined with two new concepts at that time - **MaxPooling** and **ReLU** activation gave their model an edge.\n",
    "\n",
    "You can see the various layers and their configuration in the figure above. The layers are describe in the table below:\n",
    "\n",
    "|Layer No|Layer Type|Configuration|Output Shape|\n",
    "|:------:|:--------:|:-----------:|:----------:|\n",
    "|1      |Convolution|kernel size=11x11<br/>strides=4x4<br/>filters=96<br/>padding='valid'|55x55x96|\n",
    "|2      |MaxPooling |size=3x3<br/>strides=2x2|27x27x96|\n",
    "|3      |Convolution|kernel size=5x5<br/>strides=1x1<br/>filters=256<br/>padding='same'|27x27x256|\n",
    "|4      |MaxPooling |size=3x3<br/>strides=2x2|13x13x256|\n",
    "|5      |Convolution|kernel size=3x3<br/>strides=1x1<br/>filters=384<br/>padding='same'|13x13x384|\n",
    "|6      |Convolution|kernel size=3x3<br/>strides=1x1<br/>filters=384<br/>padding='same'|13x13x384|\n",
    "|7      |Convolution|kernel size=3x3<br/>strides=1x1<br/>filters=256<br/>padding='same'|13x13x256|\n",
    "|8      |MaxPooling |size=3x3<br/>strides=2x2|6x6x256 = 9216|\n",
    "|9      |Fully Connected|units=4096|4096|\n",
    "|10     |Fully Connected|units=4096|4096|\n",
    "|11     |Fully Connected|units=1000<br/>softmax activation|1000|\n",
    "\n",
    "**Note: ReLU activation is applied to output of every Convolution and Fully Connected layer except the last softmax layer**\n",
    "\n",
    "Various other techniques were used by the authors (few of them discussed in upcoming posts) - dropout, augmentation and Stochastic Gradient Descent with momentum. \n",
    "\n",
    "### AlexNet - Code\n",
    "**ADD Git gist here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGGNet - Simonyan et al\n",
    "The runner up of 2014 imagenet challenge is named [VGGNet](https://arxiv.org/pdf/1409.1556.pdf). Because of the simplicity of it's uniform architecture it appeals to a new comer as a more simpler form of a deep convolutional neural networks.\n",
    "\n",
    "In future applications we will see how this is one of the most used choice for feature extraction from images (taking images and converting them to a smaller dimensional array that contains important information regarding the image).\n",
    "\n",
    "![](images/vggnet.jpg)\n",
    "\n",
    "### VGGNet - Architecture\n",
    "VGGNet has 2 simple rule of thumb to be followed:\n",
    "1. Each Convolutional layer have configuration - kernel size = 3x3, stride = 1x1, padding = same. The only thing that differs is number of filters.\n",
    "2. Each Max Pooling layer have configuration - windows size = 2x2 and stride = 2x2. Thus we halve the size of the image at every Pooling layer.\n",
    "\n",
    "The input image was an RGB image of 224x224 pixels. So input size = 224x224x3\n",
    "\n",
    "|Stage|Layer No|Layer Type                  |Output     |\n",
    "|:---:|:------:|:--------------------------:|:---------:|\n",
    "|1    |1       |Convolution (64 filters)    |224x224x64 |\n",
    "|1    |2       |Convolution (64 filters)    |224x224x64 |\n",
    "|-    |-       |MaxPooling                  |112x112x64 |\n",
    "|2    |1       |Convolution (128 filters)   |112x112x128|\n",
    "|2    |2       |Convolution (128 filters)   |112x112x128|\n",
    "|-    |-       |MaxPooling                  |56x56x128  |\n",
    "|3    |1       |Convolution (256 filters)   |56x56x256  |\n",
    "|3    |2       |Convolution (256 filters)   |56x56x256  |\n",
    "|3    |3       |Convolution (256 filters)   |56x56x256  |\n",
    "|-    |-       |MaxPooling                  |28x28x256  |\n",
    "|4    |1       |Convolution (512 filters)   |28x28x512  |\n",
    "|4    |2       |Convolution (512 filters)   |28x28x512  |\n",
    "|4    |3       |Convolution (512 filters)   |28x28x512  |\n",
    "|-    |-       |MaxPooling                  |14x14x256  |\n",
    "|5    |1       |Convolution (512 filters)   |14x14x512  |\n",
    "|5    |2       |Convolution (512 filters)   |14x14x512  |\n",
    "|5    |3       |Convolution (512 filters)   |14x14x512  |\n",
    "|-    |-       |MaxPooling                  |7x7x512    |\n",
    "|-    |-       |Fully Connected (4096 units)|4096       |\n",
    "|-    |-       |Fully Connected (4096 units)|4096       |\n",
    "|-    |-       |Fully Connected (1000 units)|1000       |\n",
    "|-    |-       |Softmax                     |1000       |\n",
    "\n",
    "Total Params = 138 million. Most of these parameters are contributed by fully connected layers.\n",
    "\n",
    "* The first FC layer contributes = `4096 * (7 * 7 * 512) + 4096 = 102,764,544`\n",
    "* The second FC layer contributes = `4096 * 4096 + 4096 = 16,781,312`\n",
    "* The third FC layer contributes = `4096 * 1000 + 4096 = 4,100,096`\n",
    "\n",
    "Total params contributed by FC layers = `123,645,952`.\n",
    "\n",
    "### VGGNet - Code\n",
    "\n",
    "**ADD Git Gist code**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GoogLeNet/Inception - Szegedy et al\n",
    "The winner of the 2014 imagenet competition - GoogLeNet (a.k.a [Inception v1](https://arxiv.org/pdf/1409.4842.pdf)), achieved a top-5 error rate of 6.67%. It used an inception module, a novel concept, with smaller convolutions that allowed the reduction of number of parameters to a mere 4 million.\n",
    "\n",
    "|![](images/inception_modules.jpg)|\n",
    "|:-------------------------------:|\n",
    "|*Inception Modules. Src: [Going deeper with convolutions](https://arxiv.org/pdf/1409.4842.pdf)*|\n",
    "\n",
    "Reasons for using these inception modules:\n",
    "1. Each layer type extract different information from input. Information gathered from a 3x3 layer will differ from information gathered from a 5x5 layer. How do we know which transformation will be best at the given layer? So we use all!\n",
    "2. Dimensionality reduction using 1x1 convolutions! Consider a 128x128x256 input. If we pass it through 20 filters of size 1x1 we will get an output of 128x128x20. So we apply them before the 3x3 or 5x5 convolutions to decrease the number of input filters to these layers in the inception block used for dimensionality reduction.\n",
    "\n",
    "### GoogLeNet/Inception - Architecture\n",
    "The complete inception architecture:\n",
    "\n",
    "|![](images/inception.jpg)|\n",
    "|:-------------------------------:|\n",
    "|* Src: [Going deeper with convolutions](https://arxiv.org/pdf/1409.4842.pdf)*|\n",
    "\n",
    "![](images/inception_blocks.jpg)\n",
    "\n",
    "You might see some \"auxiliary classifiers\" with softmax in this structure. Quoting paper here on this one - \"By adding auxiliary classifiers connected to these intermediate layers, we would expect to encourage discrimination in the lower stages in the classifier, increase the gradient signal that gets propagated back, and provide additional regularization.\"\n",
    "\n",
    "But what does it mean? Basically what they meant by:\n",
    "1. **discrimination in the lower stages**: We will train lower layers in network with gradients coming in from an earlier staged layer for output probabilities. This makes sure that the network has some discrimination earlier on about different objects.\n",
    "2. **increase the gradient signal that gets propagated back**: In deep neural networks, often, the gradients flowing back (using backpropagation), becomes so small that the earlier layers of network hardly learn. The earlier classification layers thus makes it helpful by propagating a strong gradient signal to train the network.\n",
    "3. **provide additional regularization**: Deep Neural Networks tend to overfit (or cause high variance) the data while small Neural Networks tend to underfit (or cause high bias). The earlier layers regularize overfitting effect of the deeper layers!\n",
    "\n",
    "Structure of Auxiliary classifiers:\n",
    "\n",
    "|Layer No|Layer Type     |Configuration|\n",
    "|:------:|:-------------:|:-----------:|\n",
    "|1       |Average Pooling|kernel size=5x5<br/>strides=3x3|\n",
    "|2       |Convolution    |kernel size=1x1<br/>filters=128<br/>activation=ReLU|\n",
    "|3       |Fully Connected|units=1024<br/>activation=ReLu|\n",
    "|4       |Dropout        |0.7 ratio of dropout units|\n",
    "|5       |Fully Connected|units=1000<br/>activation=softmax|\n",
    "\n",
    "Auxiliary classifiers were applied to inception block 4 stage a and d\n",
    "\n",
    "GoogLeNet Architecture:\n",
    "\n",
    "***\n",
    "**NOTE**: Here,\n",
    "* **#1x1** represents the filters in 1x1 convolution in inception module.\n",
    "* **#3x3 reduce** represents the filters in 1x1 convolution before 3x3 convolution in inception module.\n",
    "* **#5x5 reduce** represents the filters in 1x1 convolution before 5x5 convolution in inception module.\n",
    "* **#3x3** represents the filters in 3x3 convolution in inception module.\n",
    "* **#5x5** represents the filters in 5x5 convolution in inception module.\n",
    "* **Pool Proj** represents the filters in 1x1 convolution before Max Pool in inception module.\n",
    "***\n",
    "\n",
    "|Block|Stage|Layer Type     |Configuration|Output Shape|#1x1|#3x3<br/>reduce|#3x3|#5x5<br/>reduce|#5x5|pool proj|\n",
    "|:---:|:---:|:-------------:|:-----------:|:----------:|:--:|:-------------:|:--:|:-------------:|:--:|:---:|\n",
    "|1    |-    |Convolution    |kernel size=7x7<br/>strides=2x2<br/>filters=64|112x112x64|-|-|-|-|-|-|\n",
    "|1    |-    |Max Pool       |size=3x3<br/>strides=2x2|56x56x64|-|-|-|-|-|-|\n",
    "|2    |-    |Convolution    |kernel size=1x1<br/>filters=64 |56x56x64|-|-|-|-|-|-|\n",
    "|2    |-    |Convolution    |kernel size=3z3<br/>strides=1x1<br/>filters=192<br/>padding=same|56x56x192|-|-|-|-|-|-|\n",
    "|2    |-    |Max Pool       |size=3x3<br/>strides=2x2|28x28x192|-|-|-|-|-|-|\n",
    "|3    |a    |Inception      |-|28x28x256|64|96|128|16|32|32|\n",
    "|3    |b    |Inception      |-|28x28x480|128|128|192|32|96|64|\n",
    "|3    |-    |Max Pool       |size=3x3<br/>strides=2x2|14x14x480|-|-|-|-|-|-|\n",
    "|4    |a    |Inception      |-|14x14x512|192|96|208|16|48|64|\n",
    "|4    |b    |Inception      |-|14x14x512|160|112|224|24|64|64|\n",
    "|4    |c    |Inception      |-|14x14x512|128|128|256|24|64|64|\n",
    "|4    |d    |Inception      |-|14x14x528|112|144|288|32|64|64|\n",
    "|4    |e    |Inception      |-|14x14x832|256|160|320|32|128|128|\n",
    "|4    |-    |Max Pool       |size=3x3<br/>strides=2x2|7x7x832|-|-|-|-|-|-|\n",
    "|5    |a    |Inception      |-|7x7x832|256|160|320|32|128|128|\n",
    "|5    |b    |Inception      |-|7x7x1024|384|192|384|48|128|128|\n",
    "|6    |-    |Avg Pool       |size=7x7<br/>strides=1x1|1x1x1024|-|-|-|-|-|-|\n",
    "|6    |-    |Dropout        |p=0.4|1x1x1024|-|-|-|-|-|-|\n",
    "|7    |-    |Fully Connected|units=1000<br/>activation=softmax|1x1x1024|-|-|-|-|-|-|\n",
    "\n",
    "It used batch normalization, image distortions and RMSprop. Things we will discuss in future posts.\n",
    "\n",
    "### GoogLeNet/Inception - Code\n",
    "\n",
    "**Add git gist**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet - Kaiming He et al\n",
    "The 2015 imagenet competition brought about a top-5 error rate of 3.57%, which is lower than the human error on top-5. This was due to ResNet (Residual Network) model used by microsoft at the competition. The network introduced a novel approach called - \"skip connections\".\n",
    "\n",
    "|![](images/resnet_block.jpg)|\n",
    "|:-------------------------:|\n",
    "|*ResNet Block Displaying skip connection. Source: [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf)*|\n",
    "\n",
    "The idea came out as a solution to an observation - *Deep neural networks perfrom worse as we keep on adding layer*. But intuitively speaking, this should not be the case. If a network with k layers performs as y, then a network with k+1 layers should atleast perform y.\n",
    "\n",
    "The observation brought about a hypothesis: *direct mappings are hard to learn*. So instead of learning mapping between output of layer and its input, learn the difference between them - learn the *residual*.\n",
    "\n",
    "Say x was the input and H(x) was the learnt output. So, we need to learn F(x) = H(x) - x. We can do this by first making a layer to learn F(x) and then adding x to F(x) hence achieving H(x). As a result we are sending the same H(x) in next layer as we were supposed to before! This gave rise to the residual block we saw above.\n",
    "\n",
    "The results were amazing as the vanishing gradients problem which usually make deep neural networks numb to learning were removed. How? The skip connections or the shortcuts, as we might say them, gave a shortcut to the gradients to the previous layers, skipping bunch of layers in between.\n",
    "\n",
    "### ResNet - Architecture\n",
    "\n",
    "|![](images/resnet.jpg)|\n",
    "|:--------------------:|\n",
    "|*34 layer deep ResNet. Source: [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf)*|\n",
    "\n",
    "The paper - [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf) have a well defined table describing the architecture let's use it here:\n",
    "\n",
    "<style>\n",
    "    .mat_row_beg{\n",
    "        border-left: 3px solid black;\n",
    "        border-right: 3px solid black;\n",
    "        border-radius: 30% 30% 0 0;\n",
    "        padding:3px;\n",
    "    }\n",
    "\n",
    "    .mat_row_mid {\n",
    "        border-left: 3px solid black;\n",
    "        border-right: 3px solid black;\n",
    "        padding:3px;\n",
    "    }\n",
    "\n",
    "    .mat_row_end{\n",
    "        border-left: 3px solid black;\n",
    "        border-right: 3px solid black;\n",
    "        border-radius: 0 0 30% 30%;\n",
    "        padding:3px;\n",
    "    }\n",
    "</style>\n",
    "<div style=\"overflow-x: auto\">\n",
    "    <table style=\"font-size:15px;\">\n",
    "        <tbody>\n",
    "            <tr>\n",
    "                <th style=\"text-align:center;padding:8px;\">Layer Name</th>\n",
    "                <th style=\"text-align:center;padding:8px;\">Output Size</th>\n",
    "                <th style=\"text-align:center;padding:8px;\">18-layer</th>\n",
    "                <th style=\"text-align:center;padding:8px;\">34-layer</th>\n",
    "                <th style=\"text-align:center;padding:8px;\">50-layer</th>\n",
    "                <th style=\"text-align:center;padding:8px;\">101-layer</th>\n",
    "                <th style=\"text-align:center;padding:8px;\">152-layer</th>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"text-align:center;padding:8px;\">conv1</td>\n",
    "                <td style=\"text-align:center;padding:8px;\">112x112</td>\n",
    "                <td colspan=\"5\" style=\"text-align:center;padding:8px;\">7x7, 64, stride 2</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td colspan=\"7\" style=\"text-align:center;padding:8px;\">3x3 max pool, stride 2</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"text-align:center;padding:8px;\">conv2_x</td>\n",
    "                <td style=\"text-align:center;padding:8px;\">56x56</td>\n",
    "                <td style=\"text-align:center;padding:8px;\">\n",
    "                    <table cellspacing=\"0\">\n",
    "                        <tr>\n",
    "                            <td class=\"mat_row_beg\">3x3, 64</td>\n",
    "                            <td rowspan=\"2\" style=\"padding:3px\">x 2</td>\n",
    "                        </tr>\n",
    "                        <tr><td  class=\"mat_row_end\">3x3, 64</td></tr>\n",
    "                    </table>\n",
    "                </td>\n",
    "                <td style=\"text-align:center;padding:8px;\">\n",
    "                    <table cellspacing=\"0\">\n",
    "                        <tr>\n",
    "                            <td class=\"mat_row_beg\">3x3, 64</td>\n",
    "                            <td rowspan=\"3\" style=\"padding:3px\">x 3</td>\n",
    "                        </tr>\n",
    "                        <tr><td  class=\"mat_row_end\">3x3, 64</td></tr>\n",
    "                    </table>\n",
    "                </td>\n",
    "                <td style=\"text-align:center;padding:8px;\">\n",
    "                    <table cellspacing=\"0\">\n",
    "                        <tr>\n",
    "                            <td class=\"mat_row_beg\">1x1, 64</td>\n",
    "                            <td rowspan=\"3\" style=\"padding:3px\">x 3</td>\n",
    "                        </tr>\n",
    "                        <tr><td class=\"mat_row_mid\">3x3, 64</td></tr>\n",
    "                        <tr><td class=\"mat_row_end\">1x1, 256</td></tr>\n",
    "                    </table>\n",
    "                </td>\n",
    "                <td style=\"text-align:center;padding:8px;\">\n",
    "                    <table cellspacing=\"0\">\n",
    "                        <tr>\n",
    "                            <td class=\"mat_row_beg\">1x1, 64</td>\n",
    "                            <td rowspan=\"3\" style=\"padding:3px\">x 3</td>\n",
    "                        </tr>\n",
    "                        <tr><td class=\"mat_row_mid\">3x3, 64</td></tr>\n",
    "                        <tr><td class=\"mat_row_end\">1x1, 256</td></tr>\n",
    "                    </table>\n",
    "                </td>\n",
    "                <td style=\"text-align:center;padding:8px;\">\n",
    "                    <table cellspacing=\"0\">\n",
    "                        <tr>\n",
    "                            <td class=\"mat_row_beg\">1x1, 64</td>\n",
    "                            <td rowspan=\"3\" style=\"padding:3px\">x 3</td>\n",
    "                        </tr>\n",
    "                        <tr><td class=\"mat_row_mid\">3x3, 64</td></tr>\n",
    "                        <tr><td class=\"mat_row_end\">1x1, 256</td></tr>\n",
    "                    </table>\n",
    "                </td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"text-align:center;padding:8px;\">conv3_x</td>\n",
    "                <td style=\"text-align:center;padding:8px;\">28x28</td>\n",
    "                <td style=\"text-align:center;padding:8px;\">\n",
    "                    <table cellspacing=\"0\">\n",
    "                        <tr>\n",
    "                            <td class=\"mat_row_beg\">3x3, 128</td>\n",
    "                            <td rowspan=\"2\" style=\"padding:3px\">x 2</td>\n",
    "                        </tr>\n",
    "                        <tr><td  class=\"mat_row_end\">3x3, 128</td></tr>\n",
    "                    </table>\n",
    "                </td>\n",
    "                <td style=\"text-align:center;padding:8px;\">\n",
    "                    <table cellspacing=\"0\">\n",
    "                        <tr>\n",
    "                            <td class=\"mat_row_beg\">3x3, 128</td>\n",
    "                            <td rowspan=\"3\" style=\"padding:3px\">x 4</td>\n",
    "                        </tr>\n",
    "                        <tr><td  class=\"mat_row_end\">3x3, 128</td></tr>\n",
    "                    </table>\n",
    "                </td>\n",
    "                <td style=\"text-align:center;padding:8px;\">\n",
    "                    <table cellspacing=\"0\">\n",
    "                        <tr>\n",
    "                            <td class=\"mat_row_beg\">1x1, 128</td>\n",
    "                            <td rowspan=\"3\" style=\"padding:3px\">x 4</td>\n",
    "                        </tr>\n",
    "                        <tr><td class=\"mat_row_mid\">3x3, 128</td></tr>\n",
    "                        <tr><td class=\"mat_row_end\">1x1, 512</td></tr>\n",
    "                    </table>\n",
    "                </td>\n",
    "                <td style=\"text-align:center;padding:8px;\">\n",
    "                    <table cellspacing=\"0\">\n",
    "                        <tr>\n",
    "                            <td class=\"mat_row_beg\">1x1, 128</td>\n",
    "                            <td rowspan=\"3\" style=\"padding:3px\">x 4</td>\n",
    "                        </tr>\n",
    "                        <tr><td class=\"mat_row_mid\">3x3, 128</td></tr>\n",
    "                        <tr><td class=\"mat_row_end\">1x1, 512</td></tr>\n",
    "                    </table>\n",
    "                </td>\n",
    "                <td style=\"text-align:center;padding:8px;\">\n",
    "                    <table cellspacing=\"0\">\n",
    "                        <tr>\n",
    "                            <td class=\"mat_row_beg\">1x1, 128</td>\n",
    "                            <td rowspan=\"3\" style=\"padding:3px\">x 8</td>\n",
    "                        </tr>\n",
    "                        <tr><td class=\"mat_row_mid\">3x3, 128</td></tr>\n",
    "                        <tr><td class=\"mat_row_end\">1x1, 512</td></tr>\n",
    "                    </table>\n",
    "                </td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"text-align:center;padding:8px;\">conv4_x</td>\n",
    "                <td style=\"text-align:center;padding:8px;\">14x14</td>\n",
    "                <td style=\"text-align:center;padding:8px;\">\n",
    "                    <table cellspacing=\"0\">\n",
    "                        <tr>\n",
    "                            <td class=\"mat_row_beg\">3x3, 256</td>\n",
    "                            <td rowspan=\"2\" style=\"padding:3px\">x 2</td>\n",
    "                        </tr>\n",
    "                        <tr><td  class=\"mat_row_end\">3x3, 256</td></tr>\n",
    "                    </table>\n",
    "                </td>\n",
    "                <td style=\"text-align:center;padding:8px;\">\n",
    "                    <table cellspacing=\"0\">\n",
    "                        <tr>\n",
    "                            <td class=\"mat_row_beg\">3x3, 256</td>\n",
    "                            <td rowspan=\"3\" style=\"padding:3px\">x 6</td>\n",
    "                        </tr>\n",
    "                        <tr><td  class=\"mat_row_end\">3x3, 256</td></tr>\n",
    "                    </table>\n",
    "                </td>\n",
    "                <td style=\"text-align:center;padding:8px;\">\n",
    "                    <table cellspacing=\"0\">\n",
    "                        <tr>\n",
    "                            <td class=\"mat_row_beg\">1x1, 256</td>\n",
    "                            <td rowspan=\"3\" style=\"padding:3px\">x 6</td>\n",
    "                        </tr>\n",
    "                        <tr><td class=\"mat_row_mid\">3x3, 256</td></tr>\n",
    "                        <tr><td class=\"mat_row_end\">1x1, 1024</td></tr>\n",
    "                    </table>\n",
    "                </td>\n",
    "                <td style=\"text-align:center;padding:8px;\">\n",
    "                    <table cellspacing=\"0\">\n",
    "                        <tr>\n",
    "                            <td class=\"mat_row_beg\">1x1, 256</td>\n",
    "                            <td rowspan=\"3\" style=\"padding:3px\">x 23</td>\n",
    "                        </tr>\n",
    "                        <tr><td class=\"mat_row_mid\">3x3, 256</td></tr>\n",
    "                        <tr><td class=\"mat_row_end\">1x1, 1024</td></tr>\n",
    "                    </table>\n",
    "                </td>\n",
    "                <td style=\"text-align:center;padding:8px;\">\n",
    "                    <table cellspacing=\"0\">\n",
    "                        <tr>\n",
    "                            <td class=\"mat_row_beg\">1x1, 256</td>\n",
    "                            <td rowspan=\"3\" style=\"padding:3px\">x 36</td>\n",
    "                        </tr>\n",
    "                        <tr><td class=\"mat_row_mid\">3x3, 256</td></tr>\n",
    "                        <tr><td class=\"mat_row_end\">1x1, 1024</td></tr>\n",
    "                    </table>\n",
    "                </td>\n",
    "            </tr>\n",
    "            <td style=\"text-align:center;padding:8px;\">conv5_x</td>\n",
    "            <td style=\"text-align:center;padding:8px;\">7x7</td>\n",
    "            <td style=\"text-align:center;padding:8px;\">\n",
    "                <table cellspacing=\"0\">\n",
    "                    <tr>\n",
    "                        <td class=\"mat_row_beg\">3x3, 512</td>\n",
    "                        <td rowspan=\"2\" style=\"padding:3px\">x 2</td>\n",
    "                    </tr>\n",
    "                    <tr><td  class=\"mat_row_end\">3x3, 512</td></tr>\n",
    "                </table>\n",
    "            </td>\n",
    "            <td style=\"text-align:center;padding:8px;\">\n",
    "                <table cellspacing=\"0\">\n",
    "                    <tr>\n",
    "                        <td class=\"mat_row_beg\">3x3, 512</td>\n",
    "                        <td rowspan=\"3\" style=\"padding:3px\">x 3</td>\n",
    "                    </tr>\n",
    "                    <tr><td  class=\"mat_row_end\">3x3, 512</td></tr>\n",
    "                </table>\n",
    "            </td>\n",
    "            <td style=\"text-align:center;padding:8px;\">\n",
    "                <table cellspacing=\"0\">\n",
    "                    <tr>\n",
    "                        <td class=\"mat_row_beg\">1x1, 512</td>\n",
    "                        <td rowspan=\"3\" style=\"padding:3px\">x 3</td>\n",
    "                    </tr>\n",
    "                    <tr><td class=\"mat_row_mid\">3x3, 512</td></tr>\n",
    "                    <tr><td class=\"mat_row_end\">1x1, 2048</td></tr>\n",
    "                </table>\n",
    "            </td>\n",
    "            <td style=\"text-align:center;padding:8px;\">\n",
    "                <table cellspacing=\"0\">\n",
    "                    <tr>\n",
    "                        <td class=\"mat_row_beg\">1x1, 512</td>\n",
    "                        <td rowspan=\"3\" style=\"padding:3px\">x 3</td>\n",
    "                    </tr>\n",
    "                    <tr><td class=\"mat_row_mid\">3x3, 512</td></tr>\n",
    "                    <tr><td class=\"mat_row_end\">1x1, 2048</td></tr>\n",
    "                </table>\n",
    "            </td>\n",
    "            <td style=\"text-align:center;padding:8px;\">\n",
    "                <table cellspacing=\"0\">\n",
    "                    <tr>\n",
    "                        <td class=\"mat_row_beg\">1x1, 512</td>\n",
    "                        <td rowspan=\"3\" style=\"padding:3px\">x 3</td>\n",
    "                    </tr>\n",
    "                    <tr><td class=\"mat_row_mid\">3x3, 512</td></tr>\n",
    "                    <tr><td class=\"mat_row_end\">1x1, 2048</td></tr>\n",
    "                </table>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td colspan=\"7\" style=\"text-align:center;padding:8px;\">Global Average Pooling</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td colspan=\"7\" style=\"text-align:center;padding:8px;\">Fully Connected, units=1000</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td colspan=\"7\" style=\"text-align:center;padding:8px;\">Softmax</td>\n",
    "        </tr>\n",
    "        </tbody>\n",
    "    </table>\n",
    "</div>\n",
    "\n",
    "The paper mentions the usage of bottleneck for deeper ReNets - 50/101/152. Instead of using the residual block mentioned above the network uses 1x1 convolutions to increase and decrease dimensionality of the number of channels.\n",
    "\n",
    "|![](images/resnet_bottleneck.jpg)|\n",
    "|:-------------------------------:|\n",
    "|*Source: [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf)*|\n",
    "\n",
    "### ResNet - Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This brings us to the end of this post. In the next post we will be discussing some new architecture that have drawn quite an attention in today's deep learning world!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
